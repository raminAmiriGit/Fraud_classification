{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34a6753b-bc31-4d27-a889-0331f5752f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mistplay Fraud Demo â€“ Train & Register Model\n",
    "\n",
    "This notebook uses Feature Store to build a training set, trains a fraud classifier, tracks metrics with MLflow, and registers the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c4ebf2-d3b1-4586-8382-99fdd489d41d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea9b4046-baf7-4326-aa80-52d10cc7cc9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install databricks-feature-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40e5c199-dea0-46c7-a4b8-0521a1cecae9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python or dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b34a177b-3a8d-496a-8a33-031fe965cf43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from databricks.feature_store import FeatureStoreClient, FeatureLookup\n",
    "from pyspark.sql import functions as F\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "DB_NAME = \"ramin_.mistplay_fraud_demo\"\n",
    "MODEL_LR = \"ramin_.mistplay_fraud_demo.mistplay_fraud_model_lr\"\n",
    "MODEL_RF = \"ramin_.mistplay_fraud_demo.mistplay_fraud_model_rf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a99fee2e-99c7-4e7f-abfc-938f1e296fb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fs = FeatureStoreClient()\n",
    "\n",
    "training_base = spark.table(f\"{DB_NAME}.training_base\")\n",
    "\n",
    "lookups = [\n",
    "    FeatureLookup(table_name=f\"{DB_NAME}.account_features\", lookup_key=\"account_id\"),\n",
    "    FeatureLookup(table_name=f\"{DB_NAME}.device_features\", lookup_key=\"device_id\"),\n",
    "]\n",
    "\n",
    "training_set = fs.create_training_set(\n",
    "    training_base,\n",
    "    feature_lookups=lookups,\n",
    "    label=\"is_fraud_label\",\n",
    "    exclude_columns=[\"account_id\", \"device_id\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a88a7ca-74dc-469e-a791-d57f31e1b649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## scikitlearn package to use (normal ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b398bdb-3299-48fc-8e8e-1f86e1db9fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "training_df = training_set.load_df().toPandas()\n",
    "\n",
    "label_col = \"is_fraud_label\"\n",
    "categorical_cols = [\n",
    "    \"country\",\n",
    "    \"platform\",\n",
    "    \"marketing_channel\",\n",
    "    \"device_type\",\n",
    "    \"os_version\",\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    c for c in training_df.columns if c not in categorical_cols + [label_col]\n",
    "]\n",
    "\n",
    "X = training_df.drop(columns=[label_col])\n",
    "y = training_df[label_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"numeric\", StandardScaler(), numeric_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e9c2b9-0b6f-4036-a204-22811da9f013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0f8ab5b-ac0b-4453-9cec-fd72b314e3fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## mlflow to track metrics and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9bb1de3-1af3-485a-9ee4-8c882972d363",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_and_log(model_name: str, estimator):\n",
    "    pipeline = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", estimator)])\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        preds = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, preds)\n",
    "        pr_auc = average_precision_score(y_test, preds)\n",
    "\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"pr_auc\", pr_auc)\n",
    "\n",
    "        fs.log_model(\n",
    "            model=pipeline,\n",
    "            artifact_path=\"model\",\n",
    "            flavor=mlflow.sklearn,\n",
    "            training_set=training_set,\n",
    "            registered_model_name=model_name,\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc,\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(\n",
    "    train_and_log(\n",
    "        MODEL_LR,\n",
    "        LogisticRegression(max_iter=200, class_weight=\"balanced\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "results.append(\n",
    "    train_and_log(\n",
    "        MODEL_RF,\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=8,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3a1111-a240-4975-b122-1f1480607b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "best_row = results_df.sort_values(\"roc_auc\", ascending=False).iloc[0]\n",
    "\n",
    "best_model_name = best_row[\"model_name\"]\n",
    "best_roc_auc = float(best_row[\"roc_auc\"])\n",
    "\n",
    "best_model_df = spark.createDataFrame([\n",
    "    {\n",
    "        \"model_name\": best_model_name,\n",
    "        \"selection_metric\": \"roc_auc\",\n",
    "        \"metric_value\": best_roc_auc,\n",
    "        \"selected_at\": None,\n",
    "    }\n",
    "]).withColumn(\"selected_at\", F.current_timestamp())\n",
    "\n",
    "best_model_df.write.mode(\"overwrite\").saveAsTable(f\"{DB_NAME}.model_selection\")\n",
    "\n",
    "print(\"Registered models:\")\n",
    "print(f\"- {MODEL_LR}\")\n",
    "print(f\"- {MODEL_RF}\")\n",
    "print(\"Best model by ROC AUC:\")\n",
    "print(best_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd6e0528-40b4-431f-a20e-e3d54d17fee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02_train_register",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
